<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Statistical Process Control for Online Analytical Processing</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Overview:</li><li class="chapter-item expanded "><a href="chapter_1.html"><strong aria-hidden="true">1.</strong> The Origin of Statistical Process Control and Shewhart's Contribution</a></li><li class="chapter-item expanded "><a href="spc_control_charts/shewhart_charts.html"><strong aria-hidden="true">2.</strong> Shewhart Control Charts Overview</a></li><li class="chapter-item expanded "><a href="spc_control_charts/additional_charts.html"><strong aria-hidden="true">3.</strong> Additional Control Charts Overview</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Presentations</li><li class="chapter-item expanded "><a href="presentations/hands_on.html"><strong aria-hidden="true">4.</strong> Hands On Lab</a></li><li class="chapter-item expanded "><a href="presentations/index.html"><strong aria-hidden="true">5.</strong> Shewhart Control Charts</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="charts/run_chart.html"><strong aria-hidden="true">5.1.</strong> Run Charts</a></li><li class="chapter-item expanded "><a href="presentations/data_classification.html"><strong aria-hidden="true">5.2.</strong> Data Classification</a></li><li class="chapter-item expanded "><a href="presentations/pair_data_to_charts.html"><strong aria-hidden="true">5.3.</strong> Data to Control Chart</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.4.</strong> Variable Continuouse Data</div></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><li class="part-title">Case Study</li><li class="chapter-item expanded "><a href="spc_control_charts/charts/multivariate_control_charts.html"><strong aria-hidden="true">6.</strong> Multivariate Control Charts T-squared (Hotelling's T²)</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Appendix</li><li class="chapter-item expanded "><a href="appendix/glossory.html"><strong aria-hidden="true">7.</strong> Glossory of Terms</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="appendix/contributors.html"><strong aria-hidden="true">8.</strong> Contributors</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Statistical Process Control for Online Analytical Processing</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="the-origin-of-statistical-process-control-and-shewharts-contribution"><a class="header" href="#the-origin-of-statistical-process-control-and-shewharts-contribution">The Origin of Statistical Process Control and Shewhart's Contribution</a></h1>
<p>Statistical Process Control (SPC) is a cornerstone in the field of quality control and has played a pivotal role in the evolution of manufacturing processes. The development of SPC is intrinsically linked to the work of Walter A. Shewhart in the early 20th century.</p>
<h2 id="early-developments-in-quality-control"><a class="header" href="#early-developments-in-quality-control">Early Developments in Quality Control</a></h2>
<p>Before the 1920s, quality control in manufacturing primarily relied on post-production inspection. This method often resulted in inefficiencies, with high rates of defects and wastage.</p>
<h2 id="shewhart-at-bell-telephone-laboratories"><a class="header" href="#shewhart-at-bell-telephone-laboratories">Shewhart at Bell Telephone Laboratories</a></h2>
<p>Walter A. Shewhart worked at Bell Telephone Laboratories during the 1920s. His role in research and development required consistent quality and reliability, leading to his groundbreaking work in process control.</p>
<h2 id="shewharts-breakthrough-the-control-chart"><a class="header" href="#shewharts-breakthrough-the-control-chart">Shewhart's Breakthrough: The Control Chart</a></h2>
<p>In 1924, Shewhart developed the control chart, fundamentally changing how manufacturing processes were monitored:</p>
<ul>
<li><strong>Control Chart:</strong> This tool allowed for real-time monitoring of manufacturing processes, helping to identify when a process was deviating due to external factors.</li>
<li><strong>Statistical Control:</strong> Shewhart introduced the concept of a process being in a state of statistical control, operating with inherent variability and free from external influences.</li>
</ul>
<h2 id="shewharts-1931-book"><a class="header" href="#shewharts-1931-book">Shewhart's 1931 Book</a></h2>
<p>Shewhart's book, &quot;Economic Control of Quality of Manufactured Product,&quot; was published in 1931. It laid the theoretical foundation for SPC and introduced the Shewhart Cycle, later evolved into the PDCA (Plan-Do-Check-Act) cycle by W. Edwards Deming.</p>
<h2 id="shewharts-contributions"><a class="header" href="#shewharts-contributions">Shewhart's Contributions</a></h2>
<h3 id="statistical-theory-in-industrial-context"><a class="header" href="#statistical-theory-in-industrial-context">Statistical Theory in Industrial Context</a></h3>
<p>Shewhart was among the first to apply statistical methods practically in an industrial setting, revolutionizing quality control processes.</p>
<h3 id="quality-management-philosophy"><a class="header" href="#quality-management-philosophy">Quality Management Philosophy</a></h3>
<p>Shewhart's work transcended technical tools, influencing a broader philosophy of continuous improvement and the role of management in quality control.</p>
<h3 id="legacy-and-influence"><a class="header" href="#legacy-and-influence">Legacy and Influence</a></h3>
<p>His ideas were further developed by other quality management pioneers and continue to influence modern quality control and process improvement methodologies.</p>
<hr />
<p>In summary, Walter A. Shewhart's contributions to quality control have been transformative, shifting industries towards a more proactive and statistically informed approach to quality management. His legacy endures in modern methodologies like Total Quality Management (TQM) and Six Sigma.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shewhart-control-charts-overview"><a class="header" href="#shewhart-control-charts-overview">Shewhart Control Charts Overview</a></h1>
<p>Shewhart control charts, named after Walter A. Shewhart, are essential tools in statistical process control (SPC) for monitoring process variability. These charts are designed for various types of data and process characteristics. Below is a list of the primary types of Shewhart control charts and their applications.</p>
<h2 id="types-of-shewhart-control-charts"><a class="header" href="#types-of-shewhart-control-charts">Types of Shewhart Control Charts</a></h2>
<hr />
<h3 id="attribute-discrete-control-charts"><a class="header" href="#attribute-discrete-control-charts">Attribute (Discrete) Control Charts:</a></h3>
<h4 id="p-chart-proportion-chart"><a class="header" href="#p-chart-proportion-chart">P-Chart (Proportion Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Monitors the proportion of defective items in a process.</li>
<li><strong>Data Type:</strong> Attribute data (e.g., defective or not defective).</li>
</ul>
<h4 id="np-chart-number-defective-chart"><a class="header" href="#np-chart-number-defective-chart">NP-Chart (Number Defective Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Similar to the P-chart but tracks the count of defective items instead of the proportion.</li>
<li><strong>Ideal For:</strong> Constant sample sizes.</li>
</ul>
<h4 id="c-chart-count-chart"><a class="header" href="#c-chart-count-chart">C-Chart (Count Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Monitors the count of defects per unit when the number of opportunities for defects is constant.</li>
<li><strong>Data Type:</strong> Nonconformities (defects) in a process.</li>
</ul>
<h4 id="u-chart-defects-per-unit-chart"><a class="header" href="#u-chart-defects-per-unit-chart">U-Chart (Defects per Unit Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Similar to the C-chart but used when the number of opportunities for defects varies.</li>
<li><strong>Application:</strong> Monitors defects per unit of measure (e.g., per item, per square meter).</li>
</ul>
<hr />
<h3 id="variable-continuous-control-charts"><a class="header" href="#variable-continuous-control-charts">Variable (Continuous) Control Charts</a></h3>
<h4 id="xbar-and-r-chart-mean-and-range-chart"><a class="header" href="#xbar-and-r-chart-mean-and-range-chart">X̄bar and R Chart (Mean and Range Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Monitors the process mean and variability for subgrouped samples.</li>
<li><strong>Data Type:</strong> Continuous data.</li>
</ul>
<h4 id="xbar-and-s-chart-mean-and-standard-deviation-chart"><a class="header" href="#xbar-and-s-chart-mean-and-standard-deviation-chart">X̄bar and S Chart (Mean and Standard Deviation Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Similar to the X̄ and R chart, but uses standard deviation to measure variability.</li>
<li><strong>Ideal For:</strong> Larger sample sizes (typically n &gt; 10).</li>
</ul>
<h4 id="i-mr-chart-individuals-and-moving-range-chart"><a class="header" href="#i-mr-chart-individuals-and-moving-range-chart">I-MR Chart (Individuals and Moving Range Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Monitors individual observations and the moving range between two successive observations.</li>
<li><strong>Suitable For:</strong> Data collected individually, not in subgroups.</li>
</ul>
<hr />
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>Each Shewhart chart type is tailored for specific data types and process monitoring needs. The choice of chart depends on the data's nature (continuous or attribute), the sample size, and the specific process aspect to be monitored (e.g., process mean, variability, proportion of defects). Understanding each chart's characteristics is key to effective process monitoring and quality control.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="additional-control-charts"><a class="header" href="#additional-control-charts">Additional Control Charts:</a></h1>
<p>In Statistical Process Control (SPC), besides the widely known Shewhart charts (like X-bar and R charts), there are several specialized charts designed to monitor specific aspects of process behavior or to handle particular types of data. These specialty charts are often used in situations where traditional SPC charts may not provide the sensitivity or specificity required for complex or critical quality characteristics. Here are some of these specialty charts:</p>
<h4 id="ewma-chart-exponentially-weighted-moving-average-chart"><a class="header" href="#ewma-chart-exponentially-weighted-moving-average-chart">EWMA Chart (Exponentially Weighted Moving Average Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Detects small shifts in the process mean.</li>
<li><strong>Feature:</strong> Places more weight on recent data points.</li>
</ul>
<h4 id="cusum-chart-cumulative-sum-control-chart"><a class="header" href="#cusum-chart-cumulative-sum-control-chart">CUSUM Chart (Cumulative Sum Control Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Focuses on the cumulative sum of deviations from the target.</li>
<li><strong>Sensitivity:</strong> To small and persistent shifts in the process level.</li>
</ul>
<h4 id="multivariate-control-charts-t-squared---hotellings-t²"><a class="header" href="#multivariate-control-charts-t-squared---hotellings-t²">Multivariate Control Charts (T-squared - Hotelling's T²)</a></h4>
<ul>
<li><strong>Purpose:</strong> To monitor and control the stability and performance of a process based on multiple interrelated continuous variables, allowing for the simultaneous assessment of these variables to detect shifts in the process mean vector or changes in the covariance structure that single-variable charts might miss.</li>
<li><strong>Application:</strong> Extensively used in complex manufacturing processes, chemical production, and other industries where product quality and process stability depend on several interrelated measurements. It's particularly beneficial in situations requiring tight control over multiple dimensions or characteristics, ensuring comprehensive process monitoring and quality assurance.</li>
</ul>
<h4 id="ewma-exponentially-weighted-moving-average-chart"><a class="header" href="#ewma-exponentially-weighted-moving-average-chart">EWMA (Exponentially Weighted Moving Average) Chart</a></h4>
<ul>
<li><strong>Purpose:</strong> Designed to detect small shifts in the process mean more effectively than traditional Shewhart charts by giving more weight to recent data points.</li>
<li><strong>Use Cases:</strong> Useful in processes where small shifts are critical to detect early, such as in chemical manufacturing or in high-precision engineering.</li>
</ul>
<h4 id="multivariate-control-charts"><a class="header" href="#multivariate-control-charts">Multivariate Control Charts</a></h4>
<ul>
<li><strong>Purpose:</strong> Extend the concept of univariate control charts to monitor two or more related process variables simultaneously.</li>
<li><strong>Types:</strong>
T-Squared (T²) Charts: Already mentioned, for monitoring the mean vector of multivariate processes.
Principal Component Analysis (PCA) Based Charts: For reducing the dimensionality of the data while retaining most of the variation in the data set.
MEWMA (Multivariate EWMA) Charts: Similar to the univariate EWMA but for multivariate data, useful for detecting small shifts in multivariate processes.</li>
</ul>
<h4 id="cusum-cumulative-sum-control-chart"><a class="header" href="#cusum-cumulative-sum-control-chart">CUSUM (Cumulative Sum Control Chart)</a></h4>
<ul>
<li><strong>Purpose:</strong> Efficient at detecting small and medium shifts in the process mean. It cumulatively sums the deviations of individual process measurements from the target value or mean, enhancing the detection of small shifts.</li>
</ul>
<h4 id="demerit-or-quality-score-charts"><a class="header" href="#demerit-or-quality-score-charts">Demerit or Quality Score Charts</a></h4>
<ul>
<li><strong>Purpose:</strong> Used to monitor nonconformities or defects that vary in severity by assigning different weights or scores to different types of defects.</li>
<li><strong>Use Cases:</strong> Applicable in industries where defects are not uniform, and some defects are more critical than others, such as automotive or electronics manufacturing.</li>
</ul>
<h4 id="short-run-spc-charts"><a class="header" href="#short-run-spc-charts">Short Run SPC Charts</a></h4>
<ul>
<li><strong>Purpose:</strong> Designed for processes where the production runs are too short to establish traditional control limits, which require a large number of samples under a stable process.</li>
<li><strong>Use Cases:</strong> Useful in job-shop environments or industries where customized products are made in small quantities.</li>
</ul>
<h4 id="attribute-control-charts-for-rare-events"><a class="header" href="#attribute-control-charts-for-rare-events">Attribute Control Charts for Rare Events</a></h4>
<ul>
<li><strong>Types:</strong>
G and T Charts: These charts are useful for monitoring rare events, such as safety incidents or highly infrequent defects.</li>
</ul>
<h4 id="process-capability-analysis-charts"><a class="header" href="#process-capability-analysis-charts">Process Capability Analysis Charts</a></h4>
<ul>
<li><strong>Purpose:</strong> Not exactly for controlling the process but for assessing the capability of a process to produce output within specified limits.</li>
<li><strong>Types:</strong>
Cp, Cpk Charts: Provide a measure of a process's ability to produce output within specification limits, considering both the process variability and the process mean alignment with the target.</li>
</ul>
<p>These specialty SPC charts offer tailored approaches for specific monitoring needs, ranging from handling multivariate data, detecting small shifts, to accommodating processes with variable sample sizes or short runs. The choice of chart depends on the nature of the data, the process characteristics, and the specific monitoring objectives.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hands-on-example"><a class="header" href="#hands-on-example">Hands On Example</a></h1>
<h2 id="coffee-shop-example-description"><a class="header" href="#coffee-shop-example-description">Coffee Shop Example Description</a></h2>
<p>In this scenario, we explore a coffee shop's daily operations, focusing on various aspects like order processing times, customer satisfaction, and sales data. This coffee shop serves as a microcosm for understanding how small businesses operate and manage quality control, efficiency, and customer satisfaction. By collecting data on how long it takes to process orders, how satisfied customers are with their service, and how much revenue is generated, we can apply statistical methods to analyze and improve the coffee shop's performance.
Objective</p>
<p>The primary aim is to teach users about Statistical Process Control (SPC) using a relatable and easily understood example. SPC is a method of quality control which employs statistical methods to monitor and control a process. This helps ensure the process operates at its fullest potential to produce conforming product with minimal waste (rework or scrap). SPC can identify when a process is behaving as expected or when it deviates significantly from this state, signaling that there might be a particular cause of variation that needs to be addressed.</p>
<h2 id="goals-in-the-coffee-shop-context"><a class="header" href="#goals-in-the-coffee-shop-context">Goals in the Coffee Shop Context</a></h2>
<ul>
<li>
<p><strong>Understand Process Behavior:</strong> By analyzing order processing times, we can understand how efficiently the coffee shop operates on a daily basis. SPC charts help in identifying trends, shifts, or any outliers in the process.</p>
</li>
<li>
<p><strong>Improve Customer Satisfaction:</strong> Monitoring customer feedback through SPC charts enables us to pinpoint areas of improvement. It can reveal whether changes in the process positively or negatively affect customer satisfaction.</p>
</li>
<li>
<p><strong>Financial Performance Monitoring:</strong> Sales data analysis through SPC can highlight patterns, such as peak hours or days and the effectiveness of promotions, guiding better business decisions.</p>
</li>
<li>
<p><strong>Quality Control:</strong> Through continuous monitoring of these metrics, the coffee shop can maintain high standards of service quality, ensuring that customers receive consistent and satisfactory service.</p>
</li>
</ul>
<h2 id="teaching-approach"><a class="header" href="#teaching-approach">Teaching Approach</a></h2>
<p>Using the coffee shop example, we can teach users how to apply SPC charts, such as X-bar and R charts for order processing times, P charts for customer satisfaction, and C charts for defect tracking (e.g., incorrect orders). This practical application helps users grasp the principles of SPC in a familiar setting, making the learning process more intuitive and engaging. By analyzing mock data generated and expanded upon with each &quot;click,&quot; users learn how to interpret these charts, identify signals within the data, and make informed decisions to improve the process.</p>
<p>This hands-on approach demystifies statistical methods and provides valuable insights into how small changes can significantly impact a business's overall performance and customer satisfaction.</p>
<hr />
<h2 id="mock-data"><a class="header" href="#mock-data">Mock Data</a></h2>
<pre><code class="language-python">from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, DateType, StringType, FloatType, BooleanType
from pyspark.sql.functions import lit, rand, randn
import datetime

# Function to generate data
def generate_data(existing_df, num_records=100):
   
    &quot;&quot;&quot;
    Generate simulated data for a coffee shop.
    &quot;&quot;&quot;
    # Generate timestamps
    time_increments = np.random.normal(loc=5, scale=1, size=num_records).clip(min=1)
    timestamps = [start_datetime + timedelta(minutes=np.sum(time_increments[:i])) for i in range(1, num_records + 1)]

    # Order processing times (normally distributed around 5 minutes with a standard deviation of 2)
    order_processing_times = np.random.normal(loc=5, scale=2, size=num_records).clip(min=0)  # Ensure no negative times
    order_processing_times = order_processing_times.tolist()
    
    # Generate customer satisfaction levels
    customer_satisfaction_choices = ['Very Satisfied', 'Satisfied', 'Neutral', 'Unsatisfied', 'Very Unsatisfied']
    customer_satisfaction = np.random.choice(customer_satisfaction_choices, size=num_records).tolist()
    
    # Generate sales amounts and round them
    sales_amount = np.round(np.random.uniform(3, 20, size=num_records), 2)
    sales_amount = sales_amount.tolist()  # Convert to Python float list
    
    # Generate correctness of orders
    order_correct = np.random.choice([True, False], p=[0.9, 0.1], size=num_records)
    order_correct = list(map(bool, order_correct))
    
    # Prepare data for DataFrame creation
    data = list(zip(timestamps, customer_satisfaction, sales_amount, order_correct, order_processing_times))
    
    # Define schema
    schema = StructType([
        StructField(&quot;DateTime&quot;, TimestampType(), True),
        StructField(&quot;Customer Satisfaction&quot;, StringType(), True),
        StructField(&quot;Sales Amount ($)&quot;, FloatType(), True),
        StructField(&quot;Order Correct&quot;, BooleanType(), True),
        StructField(&quot;Order Processing Time (mins)&quot;, DoubleType(), True)
    ])
    
    # Create a DataFrame from the generated data
    new_data = spark.createDataFrame(data, schema=schema)
    
    # If there's existing data, append the new data
    if existing_df is not None and not existing_df.rdd.isEmpty():
        updated_df = existing_df.union(new_data)
    else:
        updated_df = new_data
    
    return updated_df

# Initialize Spark Session
spark = SparkSession.builder.appName(&quot;CoffeeShopDataGeneration&quot;).getOrCreate()

# Define the schema of the DataFrame
schema = StructType([
    StructField(&quot;Date&quot;, DateType(), True),
    StructField(&quot;Order Processing Time (mins)&quot;, FloatType(), True),
    StructField(&quot;Customer Satisfaction&quot;, StringType(), True),
    StructField(&quot;Sales Amount ($)&quot;, FloatType(), True),
    StructField(&quot;Order Correct&quot;, StringType(), True)
])

# Create an empty DataFrame with the defined schema
# This is your starting point and can be used as input to the generate_data function
coffee_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)


# Example: Assuming existing_df is your existing PySpark DataFrame
coffee_df = generate_data(coffee_df, 100)
</code></pre>
<hr />
<h2 id="line-chart"><a class="header" href="#line-chart">Line Chart</a></h2>
<p>Below, I'll outline the code for generating three separate line charts in a Databricks notebook, one for each of the specified metrics: Order Processing Time (mins), Sales Amount ($), and Order Correct percentage over time. Each section of code is meant to be run in its own cell within a Databricks notebook.</p>
<h3 id="1-order-processing-time-mins"><a class="header" href="#1-order-processing-time-mins">1. Order Processing Time (mins)</a></h3>
<p>This cell will calculate the average order processing time per day.</p>
<pre><code class="language-python">
# Calculate average order processing time per day
order_processing_time_daily_avg = existing_df.groupBy(&quot;Date&quot;).avg(&quot;Order Processing Time (mins)&quot;).orderBy(&quot;Date&quot;)

# Display the DataFrame for plotting in Databricks
display(order_processing_time_daily_avg)
</code></pre>
<h3 id="2-sales-amount-"><a class="header" href="#2-sales-amount-">2. Sales Amount ($)</a></h3>
<p>This cell will calculate the total sales amount per day.</p>
<pre><code class="language-python">
# Calculate total sales amount per day
sales_amount_daily_sum = existing_df.groupBy(&quot;Date&quot;).sum(&quot;Sales Amount ($)&quot;).orderBy(&quot;Date&quot;)

# Display the DataFrame for plotting in Databricks
display(sales_amount_daily_sum)
</code></pre>
<h3 id="3-order-correct-percentage"><a class="header" href="#3-order-correct-percentage">3. Order Correct Percentage</a></h3>
<p>For the Order Correct percentage, you'll first need to calculate the daily percentage of orders that were correct. This involves counting the number of correct orders per day, dividing by the total number of orders that day, and then multiplying by 100 to get a percentage.</p>
<pre><code class="language-python">
from pyspark.sql.functions import sum as _sum, count as _count, col

# Calculate daily percentage of orders that were correct
order_correct_daily_percentage = existing_df.groupBy(&quot;Date&quot;).agg(
    (_sum(col(&quot;Order Correct&quot;).cast(&quot;int&quot;)) / _count(&quot;*&quot;) * 100).alias(&quot;Order Correct Percentage&quot;)
).orderBy(&quot;Date&quot;)

# Display the DataFrame for plotting in Databricks
display(order_correct_daily_percentage)
</code></pre>
<h3 id="using-databricks-plotting-tool"><a class="header" href="#using-databricks-plotting-tool">Using Databricks Plotting Tool</a></h3>
<p>After running each cell, you can use Databricks' built-in plotting tool to create line charts for each metric. Here's how to do it for each cell's output:</p>
<ul>
<li>For the output of each cell, you'll see a table with your data and a set of options for visualization at the bottom of the cell's output area.</li>
<li>Select the 'Line' chart option from the visualization menu.</li>
<li>Configure the chart:
<ul>
<li>For the X-axis, select Date.</li>
<li>For the Y-axis, choose the corresponding metric (e.g., the average for order processing time, the sum for sales amount, and the percentage for order correctness).</li>
</ul>
</li>
<li>Apply any additional customizations as needed, such as titles, axis labels, or line colors.</li>
</ul>
<p>By following these instructions, you'll be able to visualize trends in order processing time, sales amount, and order accuracy over time, providing valuable insights into the coffee shop's daily operations and areas for potential improvement.</p>
<hr />
<h2 id="run-chart"><a class="header" href="#run-chart">Run Chart</a></h2>
<p>Creating run charts for the specified metrics involves a similar process to generating line charts, focusing on the same metrics but with an emphasis on identifying trends, shifts, or patterns over time. In a Databricks notebook, you'll use the same aggregation methods to prepare the data. A run chart essentially is a line chart with a focus on analyzing the data over time, so the preparation of data remains consistent. Below are the code snippets for each metric to be run in separate cells in a Databricks notebook.</p>
<h3 id="mean-of-median"><a class="header" href="#mean-of-median">Mean of Median</a></h3>
<p>The choice between mean and median depends on the data's distribution and the presence of outliers. The mean, providing the arithmetic average, is best used for data that is symmetrically distributed with few outliers, as it considers all values. However, it can be misleading for skewed distributions or when outliers significantly impact the average. The median, identifying the middle value, is more robust in skewed distributions or when outliers are present, as it is less affected by extreme values. For small datasets, both can be informative, but for larger datasets, the median can provide a clearer picture of central tendency in the presence of skewness or outliers.</p>
<h3 id="go-to"><a class="header" href="#go-to">GO TO:</a></h3>
<ul>
<li><a href="presentations/hands_on.html#median-as-measure-of-central-tendency">Median as Measure of Central Tendency</a></li>
<li><a href="presentations/hands_on.html#mean-as-measure-of-central-tendency">Mean as Measure of Central Tendency</a></li>
</ul>
<h3 id="median-as-measure-of-central-tendency"><a class="header" href="#median-as-measure-of-central-tendency">Median as Measure of Central Tendency</a></h3>
<h4 id="1-order-processing-time-mins-median"><a class="header" href="#1-order-processing-time-mins-median">1. Order Processing Time (mins) (Median)</a></h4>
<p>Calculate the average order processing time per day:</p>
<pre><code class="language-python">from pyspark.sql.functions import expr

# Calculate average order processing time per day
order_processing_time_daily_avg = existing_df.groupBy(&quot;Date&quot;).avg(&quot;Order Processing Time (mins)&quot;).orderBy(&quot;Date&quot;)

# Calculate the overall median of order processing times
median_order_processing_time = existing_df.approxQuantile(&quot;Order Processing Time (mins)&quot;, [0.5], 0)[0]

# Add the median as a constant column to the daily average DataFrame
order_processing_time_daily_avg = order_processing_time_daily_avg.withColumn(&quot;Median Order Processing Time&quot;, lit(median_order_processing_time))

# Display the DataFrame for plotting in Databricks as a run chart with median
display(order_processing_time_daily_avg)
</code></pre>
<h4 id="2-sales-amount--median"><a class="header" href="#2-sales-amount--median">2. Sales Amount ($) (Median)</a></h4>
<p>Calculate the total sales amount per day:</p>
<pre><code class="language-python"># Calculate total sales amount per day
sales_amount_daily_sum = existing_df.groupBy(&quot;Date&quot;).sum(&quot;Sales Amount ($)&quot;).orderBy(&quot;Date&quot;)

# Calculate the overall median of sales amounts
median_sales_amount = existing_df.approxQuantile(&quot;Sales Amount ($)&quot;, [0.5], 0)[0]

# Add the median as a constant column to the daily sum DataFrame
sales_amount_daily_sum = sales_amount_daily_sum.withColumn(&quot;Median Sales Amount&quot;, lit(median_sales_amount))

# Display the DataFrame for plotting in Databricks as a run chart with median
display(sales_amount_daily_sum)
</code></pre>
<h4 id="3-order-correct-percentage-median"><a class="header" href="#3-order-correct-percentage-median">3. Order Correct Percentage (Median)</a></h4>
<p>Calculate the daily percentage of orders that were correct:</p>
<pre><code class="language-python">from pyspark.sql.functions import sum as _sum, count as _count, col

# Calculate daily percentage of orders that were correct
order_correct_daily_percentage = existing_df.groupBy(&quot;Date&quot;).agg(
    (_sum(col(&quot;Order Correct&quot;).cast(&quot;int&quot;)) / _count(&quot;*&quot;) * 100).alias(&quot;Order Correct Percentage&quot;)
).orderBy(&quot;Date&quot;)

# Calculate the overall median of the order correct percentage
median_order_correct_percentage = order_correct_daily_percentage.approxQuantile(&quot;Order Correct Percentage&quot;, [0.5], 0)[0]

# Add the median as a constant column to the daily percentage DataFrame
order_correct_daily_percentage = order_correct_daily_percentage.withColumn(&quot;Median Order Correct Percentage&quot;, lit(median_order_correct_percentage))

# Display the DataFrame for plotting in Databricks as a run chart with median
display(order_correct_daily_percentage)
</code></pre>
<h3 id="mean-as-measure-of-central-tendency"><a class="header" href="#mean-as-measure-of-central-tendency">Mean as Measure of Central Tendency</a></h3>
<h4 id="1-order-processing-time-mins-mean"><a class="header" href="#1-order-processing-time-mins-mean">1. Order Processing Time (mins) (Mean)</a></h4>
<p>Calculate the average order processing time per day:</p>
<pre><code class="language-python">from pyspark.sql.functions import avg, lit

# Calculate average order processing time per day
order_processing_time_daily_avg = existing_df.groupBy(&quot;Date&quot;).avg(&quot;Order Processing Time (mins)&quot;).orderBy(&quot;Date&quot;)

# Calculate the overall mean of order processing times
mean_order_processing_time = existing_df.agg(avg(&quot;Order Processing Time (mins)&quot;).alias(&quot;mean&quot;)).collect()[0][&quot;mean&quot;]

# Add the mean as a constant column to the daily average DataFrame
order_processing_time_daily_avg = order_processing_time_daily_avg.withColumn(&quot;Mean Order Processing Time&quot;, lit(mean_order_processing_time))

# Display the DataFrame for plotting in Databricks as a run chart with mean
display(order_processing_time_daily_avg)
</code></pre>
<h4 id="2-sales-amount--mean"><a class="header" href="#2-sales-amount--mean">2. Sales Amount ($) (Mean)</a></h4>
<p>Calculate the total sales amount per day:</p>
<pre><code class="language-python">from pyspark.sql.functions import sum as _sum, count as _count, col

# Calculate daily percentage of orders that were correct
order_correct_daily_percentage = existing_df.groupBy(&quot;Date&quot;).agg(
    (_sum(col(&quot;Order Correct&quot;).cast(&quot;int&quot;)) / _count(&quot;*&quot;) * 100).alias(&quot;Order Correct Percentage&quot;)
).orderBy(&quot;Date&quot;)

# Calculate the overall mean of the order correct percentage
mean_order_correct_percentage = order_correct_daily_percentage.approxQuantile(&quot;Order Correct Percentage&quot;, [0.5], 0)[0]

# Add the mean as a constant column to the daily percentage DataFrame
order_correct_daily_percentage = order_correct_daily_percentage.withColumn(&quot;Mean Order Correct Percentage&quot;, lit(mean_order_correct_percentage))

# Display the DataFrame for plotting in Databricks as a run chart with mean
display(order_correct_daily_percentage)
</code></pre>
<h4 id="3-order-correct-percentage-mean"><a class="header" href="#3-order-correct-percentage-mean">3. Order Correct Percentage (Mean)</a></h4>
<p>Calculate the daily percentage of orders that were correct:</p>
<pre><code class="language-python">from pyspark.sql.functions import sum as _sum, count as _count, col

# Calculate daily percentage of orders that were correct
order_correct_daily_percentage = existing_df.groupBy(&quot;Date&quot;).agg(
    (_sum(col(&quot;Order Correct&quot;).cast(&quot;int&quot;)) / _count(&quot;*&quot;) * 100).alias(&quot;Order Correct Percentage&quot;)
).orderBy(&quot;Date&quot;)

# Calculate the overall mean of the order correct percentage
mean_order_correct_percentage = order_correct_daily_percentage.agg(avg(&quot;Order Correct Percentage&quot;).alias(&quot;mean&quot;)).collect()[0][&quot;mean&quot;]

# Add the mean as a constant column to the daily percentage DataFrame
order_correct_daily_percentage = order_correct_daily_percentage.withColumn(&quot;Mean Order Correct Percentage&quot;, lit(mean_order_correct_percentage))

# Display the DataFrame for plotting in Databricks as a run chart with mean
display(order_correct_daily_percentage)
</code></pre>
<h3 id="plotting-run-charts-in-databricks"><a class="header" href="#plotting-run-charts-in-databricks">Plotting Run Charts in Databricks</a></h3>
<p>After preparing the data as shown above, you can plot run charts using Databricks' plotting tool. The steps to visualize the data as run charts are the same as for line charts:</p>
<ul>
<li>After executing each cell, observe the table and visualization options below the output area.</li>
<li>Choose the 'Line' chart visualization type. While run charts and line charts use the same type of visualization, the interpretation focuses on process stability and trends for run charts.</li>
<li>Set up your axes:
<ul>
<li>Use Date for the X-axis.</li>
<li>For the Y-axis, select the appropriate metric (average for Order Processing Time, sum for Sales Amount, and percentage for Order Correct).</li>
</ul>
</li>
<li>Customize your chart as needed, focusing on clarity for analyzing trends and shifts over time.</li>
</ul>
<p>These run charts will help you identify any patterns, trends, or shifts in the data, which are critical for process analysis and improvement. Pay attention to runs (sequences of points above or below the measure of central tendency), trends (continuous increase or decrease), and any shifts in the process level, as these can indicate changes in the coffee shop's operations.</p>
<hr />
<h2 id="control-chart"><a class="header" href="#control-chart">Control Chart</a></h2>
<p>Shewhart control charts are a fundamental tool in statistical process control (SPC) used to determine if a manufacturing or business process is in a state of control. For the metrics chosen for the coffee shop example, different types of control charts are appropriate based on the nature of the data (continuous vs. attribute) and its distribution. Here’s the best type of Shewhart control chart for each metric:</p>
<h3 id="1-order-processing-time-mins-1"><a class="header" href="#1-order-processing-time-mins-1">1. Order Processing Time (mins)</a></h3>
<ul>
<li>
<p><strong>Metric Type:</strong> Continuous data.</p>
</li>
<li>
<p><strong>Best Control Chart:</strong> The Individuals Control Chart (I-MR Chart) is most suitable for order processing time. This chart is ideal for continuous data that comes from a process where data points are collected individually in a sequential order. It helps in monitoring the process mean and variation over time.</p>
</li>
</ul>
<h3 id="2-sales-amount--1"><a class="header" href="#2-sales-amount--1">2. Sales Amount ($)</a></h3>
<ul>
<li>
<p><strong>Metric Type:</strong> Continuous data.</p>
</li>
<li>
<p><strong>Best Control Chart:</strong> Similar to order processing time, the Individuals Control Chart (I-MR Chart) is also the best choice for monitoring sales amount. This metric represents continuous data that can vary significantly from one transaction to another, making the I-MR chart an excellent tool for identifying out-of-control signals that could indicate a need for process improvement.</p>
</li>
</ul>
<h3 id="3-order-correct-boolean-yesno"><a class="header" href="#3-order-correct-boolean-yesno">3. Order Correct (Boolean: Yes/No)</a></h3>
<ul>
<li>
<p><strong>Metric Type:</strong> Attribute data (binary outcomes).</p>
</li>
<li>
<p><strong>Best Control Chart:</strong> The P-Chart (Proportion Chart) is the most appropriate for the &quot;Order Correct&quot; metric. This chart is used for attribute data where the data can be categorized into &quot;conforming&quot; and &quot;non-conforming&quot; (or, in this case, correct and incorrect orders) and the sample size can vary. It monitors the proportion of nonconforming units in a sample, providing insights into the process's stability in terms of order accuracy.
Summary</p>
</li>
</ul>
<p>I-MR Chart for continuous data like &quot;Order Processing Time&quot; and &quot;Sales Amount,&quot; to monitor individual measurements and their variability.</p>
<p>P-Chart for attribute data like &quot;Order Correct,&quot; to track the proportion of conforming vs. non-conforming items when the sample size may vary.</p>
<p>Each chart provides a visual means of identifying trends, shifts, or instances of the process being out of control, facilitating timely interventions and continuous process improvement.</p>
<h2 id="i-mr-chart"><a class="header" href="#i-mr-chart">I-MR Chart</a></h2>
<h3 id="step-1-aggregate-daily-average-for-order-processing-time-mins"><a class="header" href="#step-1-aggregate-daily-average-for-order-processing-time-mins">Step 1: Aggregate Daily Average for &quot;Order Processing Time (mins)&quot;</a></h3>
<pre><code class="language-python">
from pyspark.sql.window import Window
from pyspark.sql.functions import lag, col, abs, avg, lit

# Assuming existing_df is your initial DataFrame
order_processing_time_daily_avg = existing_df.groupBy(&quot;Date&quot;).avg(&quot;Order Processing Time (mins)&quot;).orderBy(&quot;Date&quot;)
</code></pre>
<h3 id="step-2-calculate-moving-range-of-daily-averages"><a class="header" href="#step-2-calculate-moving-range-of-daily-averages">Step 2: Calculate Moving Range of Daily Averages</a></h3>
<pre><code class="language-python">
windowSpec = Window.orderBy(&quot;Date&quot;)

order_processing_time_daily_avg = order_processing_time_daily_avg.withColumn(&quot;PrevDayAvg&quot;, lag(&quot;avg(Order Processing Time (mins))&quot;, 1).over(windowSpec))
order_processing_time_daily_avg = order_processing_time_daily_avg.withColumn(&quot;MovingRange&quot;, abs(col(&quot;avg(Order Processing Time (mins))&quot;) - col(&quot;PrevDayAvg&quot;)))
</code></pre>
<h3 id="step-3-calculate-mean-moving-range-and-estimated-standard-deviation"><a class="header" href="#step-3-calculate-mean-moving-range-and-estimated-standard-deviation">Step 3: Calculate Mean Moving Range and Estimated Standard Deviation</a></h3>
<pre><code class="language-python">
# Calculate the mean of the Moving Range
mean_moving_range = order_processing_time_daily_avg.select(avg(&quot;MovingRange&quot;)).first()[0]

# Estimating standard deviation from the Moving Range (using d2 = 1.128 for n=2)
estimated_stddev = mean_moving_range / 1.128
</code></pre>
<h3 id="step-4-calculate-ucl-and-lcl-for-the-i-chart"><a class="header" href="#step-4-calculate-ucl-and-lcl-for-the-i-chart">Step 4: Calculate UCL and LCL for the I Chart</a></h3>
<pre><code class="language-python">
# Calculate mean of daily averages for the metric
mean_daily_avg = order_processing_time_daily_avg.select(avg(&quot;avg(Order Processing Time (mins))&quot;)).first()[0]

# Calculate UCL and LCL for I chart
ucl_i = mean_daily_avg + 3 * estimated_stddev
lcl_i = mean_daily_avg - 3 * estimated_stddev if mean_daily_avg - 3 * estimated_stddev &gt; 0 else 0

order_processing_time_daily_avg = order_processing_time_daily_avg.withColumn(&quot;UCL_I&quot;, lit(ucl_i)).withColumn(&quot;LCL_I&quot;, lit(lcl_i))
</code></pre>
<h3 id="step-5-calculate-ucl-for-the-mr-chart-lcl-is-typically-0"><a class="header" href="#step-5-calculate-ucl-for-the-mr-chart-lcl-is-typically-0">Step 5: Calculate UCL for the MR Chart (LCL is typically 0)</a></h3>
<pre><code class="language-python">
# UCL for MR chart, using fixed multiplier for n=2
ucl_mr = mean_moving_range * 3.268

order_processing_time_daily_avg = order_processing_time_daily_avg.withColumn(&quot;UCL_MR&quot;, lit(ucl_mr)).withColumn(&quot;LCL_MR&quot;, lit(0))
</code></pre>
<h3 id="final-dataframe-for-visualization"><a class="header" href="#final-dataframe-for-visualization">Final DataFrame for Visualization</a></h3>
<p>At this point, order_processing_time_daily_avg contains the following columns, ready for visualization in Databricks:</p>
<ul>
<li>Date</li>
<li>avg(Order Processing Time (mins)) (Daily average of order processing time)</li>
<li>MovingRange (Daily moving range of average order processing time)</li>
<li>UCL_I and LCL_I (Upper and lower control limits for the I chart)</li>
<li>UCL_MR (Upper control limit for the MR chart, with LCL_MR typically set to 0 or not used)</li>
</ul>
<p>Instructions for Visualization in Databricks</p>
<ul>
<li>
<p>For the I Chart: When visualizing, plot Date on the X-axis and avg(Order Processing Time (mins)), UCL_I, and LCL_I on the Y-axis to show the daily averages along with their control limits.</p>
</li>
<li>
<p>For the MR Chart: Plot Date on the X-axis and MovingRange, UCL_MR (and LCL_MR if applicable) on the Y-axis to visualize the moving range and its upper control limit.</p>
</li>
</ul>
<p>This approach ensures you're visualizing the aggregated summary data with the appropriate statistical control limits to assess process stability and control effectively.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="control-charts"><a class="header" href="#control-charts">Control Charts</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview <a href="presentations/index.html#line-chart">&gt;</a></a></h2>
<p>Control charts are a fundamental tool in Statistical Process Control (SPC), used to monitor, control, and improve process performance over time. Here are the key benefits of using control charts:</p>
<ul>
<li>
<p><strong>Process Stability and Variability Reduction:</strong> Control charts enable the monitoring of process stability and the identification of unusual variations, aiding in efforts to reduce process variability and improve consistency.</p>
</li>
<li>
<p><strong>Early Detection of Issues:</strong> They facilitate the early detection of trends, shifts, and patterns, allowing for timely corrective actions before defects or quality issues arise.</p>
</li>
<li>
<p><strong>Informed Decision-making:</strong> By distinguishing between common cause and special cause variations, control charts provide a factual basis for decision-making, reducing the likelihood of unnecessary adjustments.</p>
</li>
<li>
<p><strong>Cost Efficiency:</strong> The identification and reduction of process variability lead to lower waste, reduced rework, and fewer defects, thereby decreasing operational costs and increasing efficiency.</p>
</li>
<li>
<p><strong>Continuous Improvement and Compliance:</strong> Control charts are instrumental in continuous improvement initiatives and compliance with quality standards, offering a visual tool for tracking performance, documenting process control efforts, and communicating with stakeholders.</p>
</li>
</ul>
<hr />
<h2 id="line-chart-1"><a class="header" href="#line-chart-1">Line Chart <a href="presentations/index.html#run-chart">&gt;</a></a></h2>
<h2 id="run-chart-1"><a class="header" href="#run-chart-1">Run Chart <a href="presentations/index.html#run-chart">&gt;</a></a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="run-chart-2"><a class="header" href="#run-chart-2">Run Chart</a></h1>
<p>A run chart is a line chart of data plotted over time. In other words, a run chart graphically depicts the process performance or data values in time order. Viewing data over time gives a more accurate conclusion rather than just summary statistics.</p>
<p><img src="charts/../static/images/example.png" alt="Run Chart Image" /></p>
<p>A run chart is also known as a trend chart or a time series plot. Usually, run charts are used in the measure phase of the DMAIC project and it helps to identify trends or shifts in the process and allows testing for randomness in the process.
Difference between Run chart and control chart</p>
<p>Control charts are used to monitor the stability of the process. In other words, they measure any type of output variable over time. The goal is to see the results consistently fall within the control limits. On the control chart, both upper and control limits are defined. Typically, control limits are defined as three standard deviations from the mean. If the results fall within the control limits, then the process is stable; otherwise, it suggests that the process is not stable.</p>
<p>A run chart is similar to a control chart, but the key difference is it can reveal shifts and trends, not the process stability. Since the run chart does not have control limits, it cannot detect out-of-control conditions. However, it will graphically depict how the process is running. You can turn a run chart into a control chart by adding upper and lower control limits. A pattern or trend indicates the presence of special cause variation in the process.</p>
<h3 id="why-use-a-run-chart"><a class="header" href="#why-use-a-run-chart">Why use a run chart</a></h3>
<p>A run chart is used to determine whether or not the central tendency of the process is changing. Following are a few reasons to use a run chart</p>
<ul>
<li>Easy to construct</li>
<li>It does not require too many calculations or software’ for analysis.</li>
<li>Easy to interpret the results</li>
<li>Minimum statistical knowledge is sufficient to draw and interpret the chart</li>
</ul>
<h3 id="when-to-use-run-charts"><a class="header" href="#when-to-use-run-charts">When to use run charts</a></h3>
<ul>
<li>To visually depict how the process is performing</li>
<li>Effectively track and communicate improvements (and determine success)</li>
<li>To identify process variation and avoid unbiased actions</li>
<li>Display outputs to look for stability or instability</li>
</ul>
<h3 id="key-components-of-run-chart"><a class="header" href="#key-components-of-run-chart">Key components of Run Chart</a></h3>
<ul>
<li>Time- series: the specific time period of the output (hours, days, weeks, months); plotted on the horizontal (X) axis</li>
<li>Output: The data measurement from the completed process; plotted on the vertical (Y) axis</li>
<li>Data points: output values plotted on the chart</li>
<li>Median line: the line on the graph that shows the average of all the output measure.</li>
</ul>
<h3 id="run-chart-interpretation-rules"><a class="header" href="#run-chart-interpretation-rules">Run chart interpretation rules</a></h3>
<p>The following paragraphs are the run chart decision rules used to avoid inaccurate analysis and initiate appropriate improvement actions:</p>
<p><img src="charts/../static/images/shift.png" alt="Shift Image" /></p>
<p>Shift: – Seven or eight values in succession above or below the median line is a shift. Do not consider the points that fall on the median line as they are not toward or against the shift. A shift indicates a dramatic change in the process.</p>
<p><img src="charts/../static/images/runs.png" alt="Run Image" /></p>
<p>Runs – Too many or too few runs in the data displayed on the chart. In other words, one or more consecutive points are all lying on the same side of the line. Ignore the points exactly on the line!</p>
<p><img src="charts/../static/images/clustering.png" alt="Clustering Image" /></p>
<p>Clustering – Too few runs or groups of points in one or more areas of the plot. It indicates measurement or sampling problems.</p>
<p><img src="charts/../static/images/trend.png" alt="Trend Image" /></p>
<p>Trend – Seven or more consecutive points are increasing or decreasing. A basic rule of thumb is when a run chart exhibits seven or eight points successively up or down, then a trend is clearly present in the data and needs process improvement. This rule does not care whether the consecutive points are above, below, or crossing the median.</p>
<p><img src="charts/../static/images/mixtures.png" alt="Mixtures Image" /></p>
<p>Mixtures – Too many runs in a chart with absences of points near the median line.</p>
<p><img src="charts/../static/images/astronomical.png" alt="Astronomical Image" /></p>
<p>Astronomical Point – Astronomical points occur when there is one value that is very different from the other data values on the chart. It would be a value that is highly unlikely to occur again and would appear as an outlier.</p>
<h3 id="counting-run-chart"><a class="header" href="#counting-run-chart">Counting Run Chart</a></h3>
<p>A non-random pattern is signaled by too few or too many runs, or crossings of the median line. A run is a series of points in a row on one side of the median. In other words, one or more consecutive points are all lying on the same side of the line. If only chance is influencing the process being measured with a run chart, then there should be a regularity at which data points go above and below the median to satisfy this condition. Some points can fall exactly on the median line, which makes it hard to decide which run these points belong to. Hence, ignore if the value is exactly on the median line.</p>
<p>To apply the above-mentioned interpretation of the rules, we first need to identify the useful values/observations in the data set. This can be achieved by counting the number of runs and avoiding the values on the median line.</p>
<p>If you observe a greater or fewer number of runs than expected in the chart, that means there is a non-random pattern in the process. Swed and Eisenhart developed a chart in 1943 to determine the minimum and the maximum number of runs required for each data point to follow the random variation in the process. In other words, no special cause existed in the process.</p>
<h3 id="swed-and-eisenhart-chart"><a class="header" href="#swed-and-eisenhart-chart">Swed and Eisenhart chart</a></h3>
<p><img src="charts/../static/images/swed-eisenhart.png" alt="Swed and Eisenhart Chart Image" /></p>
<h3 id="how-to-create-run-chart"><a class="header" href="#how-to-create-run-chart">How to create run chart</a></h3>
<ul>
<li>Determine the data to be measured</li>
<li>Obtain the data – collect a minimum of 10 to 15 data points in a time sequence.</li>
<li>Plot a graph with a time sequence in the horizontal x-axis (like, hours, days, weeks) and a vertical y-axis with measuring variables.</li>
<li>Plot the data values in a time sequence</li>
<li>Compute the mean/median and draw a horizontal line in the graph</li>
<li>Analyze the graph, and observe the trends and patterns to detect special cause variation in the process</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-classification"><a class="header" href="#data-classification">Data Classification</a></h1>
<p>Determining the type of data you have and its level of measurement is crucial for statistical analysis and interpretation. Here's a structured approach to help you decide whether data is qualitative or quantitative, and then further classify it into nominal, ordinal, interval, or ratio levels. We'll also touch on identifying if quantitative data is continuous or discrete.</p>
<h2 id="step-1-qualitative-vs-quantitative"><a class="header" href="#step-1-qualitative-vs-quantitative">Step 1: Qualitative vs. Quantitative</a></h2>
<ul>
<li><strong>Qualitative Data (Categorical):</strong> This type of data represents categories or characteristics and can be used to classify subjects based on some attribute or quality. It does not involve numbers or quantities.</li>
<li><strong>Quantitative Data (Numerical):</strong> This type of data is numerical and can be measured or counted. It represents quantities or amounts.</li>
</ul>
<h2 id="step-2-for-qualitative-data"><a class="header" href="#step-2-for-qualitative-data">Step 2: For Qualitative Data</a></h2>
<ul>
<li><strong>Nominal:</strong> These are categories without any natural order or ranking. Examples include gender, race, or the brand of a product. You can count them, but you cannot meaningfully order or subtract them.</li>
<li><strong>Ordinal:</strong> These categories have a natural order or ranking, but the intervals between the ranks may not be equal. Examples include survey responses like &quot;satisfied,&quot; &quot;neutral,&quot; &quot;dissatisfied.&quot;</li>
</ul>
<h2 id="step-3-for-quantitative-data"><a class="header" href="#step-3-for-quantitative-data">Step 3: For Quantitative Data</a></h2>
<ul>
<li><strong>Interval:</strong> Interval data is numeric, where the distance between two points is meaningful. However, it lacks a true zero point, meaning you cannot make statements about how many times higher one is than another. Examples include temperature in Celsius or Fahrenheit.</li>
<li><strong>Ratio:</strong> Ratio data has all the properties of interval data, with the addition of a true zero point. This allows for statements about multiplication/division. Examples include weight, height, and income.</li>
</ul>
<h2 id="step-4-continuous-vs-discrete-quantitative-data"><a class="header" href="#step-4-continuous-vs-discrete-quantitative-data">Step 4: Continuous vs. Discrete (Quantitative Data)</a></h2>
<ul>
<li><strong>Discrete Data:</strong> This data can only take certain values (like whole numbers). It often counts something, such as the number of students in a class.</li>
<li><strong>Continuous Data:</strong> This data can take any value within a range. It often measures something, such as height, weight, or time.</li>
</ul>
<h2 id="decision-logic-flow"><a class="header" href="#decision-logic-flow">Decision Logic Flow</a></h2>
<pre><code>Is the data numerical?
    Yes: Go to step 2 (Quantitative Data).
    No: It's Qualitative Data. Determine if it's Nominal or Ordinal.
Can the data take on any value in a range, or is it countable numbers?
    Any value in a range: It's Continuous.
    Countable numbers: It's Discrete.
(If Quantitative) Does the data have a true zero point?
    Yes and distances are meaningful: Ratio.
    Distances are meaningful but no true zero: Interval.
</code></pre>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>By following these steps, you can systematically determine the type and level of measurement of your data, which is essential for choosing the correct statistical methods for analysis. This logic helps ensure that your data analysis is appropriate and meaningful.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spc-decision-tool-guide"><a class="header" href="#spc-decision-tool-guide">SPC Decision Tool Guide</a></h1>
<p>Creating a decision tool or guide for navigating through the decision logic flow to determine the appropriate type of control chart for your data in the context of Statistical Process Control (SPC) is a great idea. Below is a simplified guide that incorporates the decision logic for data type classification and further links each to a corresponding type of control chart. This tool aims to streamline the process from data classification to the selection of the appropriate SPC chart.</p>
<h2 id=""><a class="header" href="#"><img src="presentations/../static/images/shewhart_control_flow.svg" alt="Mapping Guide" /></a></h2>
<pre><code>1. Identify the Data Type and Nature
    Qualitative (Categorical) Data: Typically relates to defectives. Move to Step 2.
    Quantitative (Numerical) Data: Can relate to either defects or defectives. Move to Step 3.

2. For Qualitative Data (Defectives)
    Nominal Data:
        P-chart or NP-chart: Used for monitoring the proportion or number of defective units in a sample.
    Ordinal Data: Less common, but if applicable, adapt a P-chart or U-chart based on context.

3. For Quantitative Data
    Determine if the focus is on Defects or Defectives:
        Attribute Data (Defectives):
            P-chart or NP-chart: For defectives, when you're interested in the proportion or count of nonconforming units.
        Attribute Data (Defects):
            C-chart or U-chart: For defects, when monitoring the count of defects per unit or nonconformities per unit of measure.
        Variable Data (Can be related to both, but often involves measurements indicative of defects):
            I-MR Chart: For individual measurements, suitable when data points are independent and come from a variable process.
            X̄-R Chart: For small sample sizes (2-10), when you want to monitor the process mean and variability.
            X̄-S Chart: For larger sample sizes (&gt;10), better for accurately capturing the distribution of data.
</code></pre>
<h3 id="decision-logic-flowchart"><a class="header" href="#decision-logic-flowchart">Decision Logic Flowchart</a></h3>
<pre><code>Start: Determine if your focus is on the quality of the unit (defective) or the quantity/quality of the issues (defects).
Qualitative Data (Defectives):
    Nominal: ➜ P-chart or NP-chart
    Ordinal: Context-based ➜ Adapt P-chart or U-chart
Quantitative Data:
    For Defectives: ➜ P-chart or NP-chart
    For Defects: ➜ C-chart or U-chart
    Variable Data (Consider the nature of the measurement and focus):
        ➜ I-MR Chart, X̄-R Chart, or X̄-S Chart based on sample size and analysis needs.
</code></pre>
<h3 id="implementing-the-guide"><a class="header" href="#implementing-the-guide">Implementing the Guide</a></h3>
<p>This guide can be implemented as a flowchart, a decision-making tool in software, or even a simple checklist. For digital implementation, interactive tools or apps can provide prompts based on user input, leading to the recommended control chart type, complete with explanations and examples.
Conclusion</p>
<p>By following this guide, you can systematically determine the right type of control chart for your specific data type and scenario in statistical process control. Whether you're dealing with qualitative or quantitative data, discrete or continuous, there's a structured path to follow that ensures you select the most appropriate SPC tool for your needs.</p>
<hr />
<h3 id="industry-adaptations-of-defect-terminology-for-spc"><a class="header" href="#industry-adaptations-of-defect-terminology-for-spc">Industry Adaptations of Defect Terminology for SPC</a></h3>
<p>In non-manufacturing contexts, the terms &quot;defects&quot; and &quot;defectives&quot; might not always resonate or be applicable. Depending on the nature of the work or the industry, you might find it more relevant to use terms that reflect the quality or performance issues more closely related to your specific area. Here are some alternative terms that can be used in various non-manufacturing contexts:</p>
<ul>
<li>
<p><strong>Errors and Nonconformities:</strong> This terminology can be suitable for software development, data processing, and administrative tasks, where &quot;errors&quot; refer to specific mistakes or issues in a process or output, and &quot;nonconformities&quot; refer to instances that do not meet the set standards or expectations.</p>
</li>
<li>
<p><strong>Issues and Incidents:</strong> In service industries, such as healthcare, hospitality, or IT services, &quot;issues&quot; can refer to specific problems encountered, while &quot;incidents&quot; might denote service disruptions or failure to meet service standards.</p>
</li>
<li>
<p><strong>Variations and Non-compliances:</strong> In fields such as finance, legal, and regulatory compliance, &quot;variations&quot; can denote deviations from standard procedures or expected results, and &quot;non-compliances&quot; refer to failures to adhere to laws, regulations, or internal policies.</p>
</li>
<li>
<p><strong>Anomalies and Exceptions:</strong> For data analysis, cybersecurity, and research, &quot;anomalies&quot; could be unusual patterns or outliers in data, while &quot;exceptions&quot; are cases that fall outside of normal operational parameters.</p>
</li>
<li>
<p><strong>Faults and Failures:</strong> In engineering and IT, &quot;faults&quot; might be used to describe defects in design or function, whereas &quot;failures&quot; denote a complete breakdown or inability to perform a required function.</p>
</li>
</ul>
<p>Incorporating these terms into the decision tool involves adjusting the language to better suit the context of your work while maintaining the underlying logic of the tool. For example:</p>
<pre><code>Qualitative Data (Nonconformities/Incidents):
    Nominal Data:
        P-chart or NP-chart: Used for monitoring the proportion or number of nonconforming units or incidents in a sample.
Quantitative Data (Errors/Issues):
    Attribute Data (Nonconformities/Incidents):
        P-chart or NP-chart: For monitoring the proportion or count of nonconforming units or incidents.
    Attribute Data (Errors/Issues):
        C-chart or U-chart: For monitoring the count of issues or errors per unit or per unit of measure.
</code></pre>
<p>This adjusted terminology ensures the decision tool is relevant and understandable across various industries, enhancing its utility and applicability outside of traditional manufacturing environments.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="t-squared-hotellings-t²t-squared-hotellings-t²-method-for-multivariate-control-charts"><a class="header" href="#t-squared-hotellings-t²t-squared-hotellings-t²-method-for-multivariate-control-charts">T-squared (Hotelling's T²)T-squared (Hotelling's T²) method for Multivariate Control Charts</a></h1>
<p>The T-squared (Hotelling's T²) method for Multivariate Control Charts is an extension of Shewhart control charts to monitor and control processes based on multiple interrelated quality variables. Unlike the traditional Shewhart charts that are univariate, focusing on a single quality characteristic at a time, the T-squared method allows for simultaneous monitoring of several related quality characteristics. This approach is particularly useful in situations where the quality of a process or product depends on more than one variable, and those variables may be correlated.</p>
<h2 id="overview-of-the-t-squared-method"><a class="header" href="#overview-of-the-t-squared-method">Overview of the T-squared Method:</a></h2>
<p>The T-squared method is based on Hotelling's T² statistic, which is a multivariate equivalent of the univariate Z-score. It provides a way to test hypotheses about means of multivariate normal distributions. In the context of SPC, the T² statistic is used to determine if a set of multivariate measurements is statistically similar to a set of control measurements. The steps to develop a Multivariate Control Chart using the T-squared method are as follows:</p>
<ol>
<li>
<p>Data Collection and Preparation:</p>
<ul>
<li>Collect sample data for the multivariate process. Each sample should include measurements for all variables being monitored.</li>
<li>Ensure data is normalized if scales of measurements differ significantly among variables.</li>
</ul>
</li>
<li>
<p>Calculate the Sample Mean and Covariance Matrix:</p>
<ul>
<li>Calculate the mean vector and the covariance matrix from the historical process data (the phase I dataset), which is assumed to be in control.</li>
</ul>
</li>
<li>
<p>Compute the T-squared Statistic for New Observations:</p>
<ul>
<li>For a new sample (a vector of measurements for the monitored variables), calculate the T-squared statistic using the formula:
T2=(x−xˉ)′S−1(x−xˉ)
T2=(x−xˉ)′S−1(x−xˉ)<br />
where:
<ul>
<li>xx is the vector of new observations,</li>
<li>xˉxˉ is the mean vector of the in-control process,</li>
<li>S−1S−1 is the inverse of the covariance matrix of the in-control process,</li>
<li>T2T2 is the Hotelling's T-squared statistic.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Determine Control Limits:</p>
<ul>
<li>The upper control limit (UCL) for the T-squared chart can be determined using the χ2χ2 (chi-square) distribution:
UCL=(p⋅(n−1)⋅(n+1))n⋅(n−p)⋅Fα,p,n−p
UCL=n⋅(n−p)(p⋅(n−1)⋅(n+1))​⋅Fα,p,n−p​<br />
where:
<ul>
<li>pp is the number of variables,</li>
<li>nn is the sample size,</li>
<li>Fα,p,n−pFα,p,n−p​ is the F-distribution value at a chosen αα significance level, with degrees of freedom pp and n−pn−p.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Plot and Monitor the Chart:</p>
<ul>
<li>Plot the T-squared statistic for each new set of measurements against the UCL.</li>
<li>Investigate any points that exceed the UCL as potential signals that the process may be out of control.</li>
</ul>
</li>
</ol>
<h2 id="application"><a class="header" href="#application">Application:</a></h2>
<p>The T-squared method is widely used in industries where quality is defined by multiple interrelated variables, such as manufacturing complex components requiring tight tolerances on multiple dimensions, chemical process industries where product quality depends on a combination of factors, or any process where monitoring multiple variables simultaneously can provide a more comprehensive view of process stability and capability.</p>
<p>This approach offers a powerful tool for quality control in multivariate processes, enabling the detection of out-of-control conditions that might not be identified by monitoring variables individually. However, it requires a solid understanding of multivariate statistics and careful consideration of the relationships among the variables being monitored.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="glossory-of-terms"><a class="header" href="#glossory-of-terms">Glossory of Terms</a></h1>
<h4 id="control-chart-1"><a class="header" href="#control-chart-1">Control Chart:</a></h4>
<ul>
<li>A control chart is one of the primary techniques of statistical process control (SPC). The control chart is a graphical display of quality characteristics that have been measured or computed from a sample versus the sample number or time. The control chart was invented by Walter Shewhart at Bell Labs in 1920.</li>
</ul>
<h4 id="statistical-process-control"><a class="header" href="#statistical-process-control">Statistical Process Control:</a></h4>
<ul>
<li>Statistical Process Control (SPC) is a statistical method to measure, monitor, and control a process. In other words, SPC is a quality control method that employs statistical methods to measure, monitor, and control a process.</li>
</ul>
<h4 id="common-cause"><a class="header" href="#common-cause">Common Cause:</a></h4>
<ul>
<li>A cause of variation in the process is due to chance but not assignable to any factor. It is the variation that is inherent in the process. A process under the influence of a common cause will always be stable and predictable.</li>
</ul>
<h4 id="assignable-cause-special-cause"><a class="header" href="#assignable-cause-special-cause">Assignable Cause (“Special Cause”):</a></h4>
<ul>
<li>The variation in a process that is not due to chance can be identified and eliminated. A process under the influence of a special cause will not be stable and predictable.</li>
</ul>
<h4 id="rational-sub-grouping"><a class="header" href="#rational-sub-grouping">Rational Sub-Grouping:</a></h4>
<ul>
<li>Rational sub-grouping is the process of organizing the data into groups produced under the same conditions. Rational subgroups help in the estimation process of short-term variations. Thus, rational subgrouping is the basis for operating control charts in a successful manner. These variations later help us predict the long-term variations and their control limits, depending o the type of causes for the variation (special or common).</li>
</ul>
<h4 id="quantitative-data--"><a class="header" href="#quantitative-data--">Quantitative Data: -</a></h4>
<h4 id="qualitative-data--"><a class="header" href="#qualitative-data--">Qualitative Data: -</a></h4>
<h4 id="continuoue-data--"><a class="header" href="#continuoue-data--">Continuoue Data: -</a></h4>
<h4 id="discrete-data--"><a class="header" href="#discrete-data--">Discrete Data: -</a></h4>
<h4 id="nominal-data--"><a class="header" href="#nominal-data--">Nominal Data: -</a></h4>
<h4 id="ordinal-data--"><a class="header" href="#ordinal-data--">Ordinal Data: -</a></h4>
<h4 id="interval-data--"><a class="header" href="#interval-data--">Interval Data: -</a></h4>
<h4 id="ratio-data--"><a class="header" href="#ratio-data--">Ratio Data: -</a></h4>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributors"><a class="header" href="#contributors">Contributors</a></h1>
<h2 id="eric-barber"><a class="header" href="#eric-barber">Eric Barber</a></h2>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="editor.js"></script>
        <script src="mode-rust.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
